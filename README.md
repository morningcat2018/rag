å†…å®¹æ•´ç†è‡ª <https://www.bilibili.com/video/BV1wc3izUEUb>
```
æœ¬æœºç¯å¢ƒ:macosx_26_0_x86_64

æ‰€ä»¥ä¸èƒ½ä½¿ç”¨torch>2.2.0ç‰ˆæœ¬
onnxruntimeéœ€è¦ä½¿ç”¨1.15.0ç‰ˆæœ¬
pythonéœ€è¦ä½¿ç”¨python3.11
numpyåªèƒ½ä½¿ç”¨1.xç‰ˆæœ¬
sentence-transformersä½¿ç”¨2.6.1ç‰ˆæœ¬
```

æ‰§è¡Œæ­¥éª¤
```
. /opt/anaconda3/bin/activate && conda activate /opt/anaconda3/envs/rag;
# æ­¤condaç¯å¢ƒä¸‹æ—¶ python3.11
uv init .

uv add "numpy<2"
uv add torch==2.2.0
uv add onnxruntime==1.15.0
uv add sentence_transformers chromadb google-genai python-dotenv

uv remove sentence-transformers
uv add sentence-transformers==2.6.1

uv run --with jupyter jupyter lab
```

éœ€è¦åœ¨[google aistudio](https://aistudio.google.com/api-keys)ç”³è¯·API key;
å¹¶åœ¨é¡¹ç›®ç›®å½•ä¸‹åˆ›å»º .env æ–‡ä»¶,å†…å®¹ä¸º
```
GEMINI_API_KEY=æ­¤å¤„å¡«å†™ç”³è¯·çš„keyå€¼
```

pyproject.toml
```toml
[project]
name = "rag"
version = "0.1.0"
description = "æ„å»ºRAGç³»ç»Ÿ"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "chromadb>=1.5.0",
    "google-genai>=1.64.0",
    "numpy<2",
    "onnxruntime==1.15.0",
    "python-dotenv>=1.2.1",
    "sentence-transformers==2.6.1",
    "torch==2.2.0",
]
```

## å‘é‡æ•°æ®åº“ qdrant

https://qdrant.org.cn/documentation/quickstart/

ä¸‹è½½: https://github.com/qdrant/qdrant/releases

å¯åŠ¨: qdrant --storage-path ~/.local/share/qdrant

è®¿é—®æµ‹è¯•ï¼šhttp://localhost:6333

æ•°æ®ç›®å½• é»˜è®¤åœ¨ï¼šå½“å‰ç›®å½•ä¸‹çš„ storage/

å¯æŒ‡å®šï¼š qdrant --storage-path /è‡ªå®šä¹‰è·¯å¾„

### curl è®¿é—®

åˆ›å»º Collection

```curl
curl -X PUT "http://localhost:6333/collections/my_collection" \
  -H "Content-Type: application/json" \
  -d '{
    "vectors": {
      "size": 768,
      "distance": "Cosine"
    }
}'
```

æ’å…¥æ•°æ®

```curl
curl -X PUT "http://localhost:6333/collections/my_collection/points" \
  -H "Content-Type: application/json" \
  -d '{
    "points": [
      {
        "id": 1,
        "vector": [0.01, 0.02, ..., 0.99],
        "payload": {
          "text": "è¿™æ˜¯ç¬¬ä¸€æ®µæ–‡æœ¬",
          "source": "doc1"
        }
      }
    ]
}'
```

å‘é‡æœç´¢

```curl
curl -X POST "http://localhost:6333/collections/my_collection/points/search" \
  -H "Content-Type: application/json" \
  -d '{
    "vector": [0.01, 0.02, ..., 0.99],
    "limit": 3
}'
```

```curl
curl -X DELETE http://localhost:6333/collections/my_collection
```

```curl
curl http://localhost:6333/collections
```


### Python ä½¿ç”¨ï¼ˆæ¨èæ–¹å¼ï¼‰

> pip install qdrant-client

or

> uv add qdrant-client

```py
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct

client = QdrantClient("localhost", port=6333)

# åˆ›å»ºé›†åˆ
client.create_collection(
    collection_name="my_collection",
    vectors_config=VectorParams(size=768, distance=Distance.COSINE),
)

# æ’å…¥æ•°æ®
client.upsert(
    collection_name="my_collection",
    points=[
        PointStruct(
            id=1,
            vector=[0.01]*768,
            payload={"text": "æµ‹è¯•æ–‡æœ¬"}
        )
    ],
)

# æŸ¥è¯¢
hits = client.search(
    collection_name="my_collection",
    query_vector=[0.01]*768,
    limit=3,
)

print(hits)
```

## embedding model

1. shibing624/text2vec-base-chinese

æœ¬æœºç¼“å­˜ä½ç½® ~/.cache/huggingface/hub

- ğŸ“Œ æ¨¡å‹ç±»å‹ï¼š åŸºäº CoSENTï¼ˆCosine Sentenceï¼‰è®­ç»ƒçš„æ–¹æ³•ï¼Œä¸Šå±‚ä¸ºä¸€ä¸ª Transformer ç¼–ç å™¨ï¼Œåº•å±‚ä½¿ç”¨ pooling å¾—åˆ°å¥å­å‘é‡ã€‚
- ğŸ§  åŸºç¡€ç»“æ„ï¼š å†…éƒ¨ä½¿ç”¨ hfl/chinese-macbert-base é¢„è®­ç»ƒæ¨¡å‹ä½œä¸ºè¯è¡¨ç¤ºåŸºç¡€ï¼Œå†é€šè¿‡å¯¹æ¯”å­¦ä¹ ï¼ˆcontrastive learningï¼‰æ–¹å¼ fine-tuneã€‚
- ğŸ“Š è¾“å‡ºå‘é‡ï¼š æŠŠå¥å­æ˜ å°„åˆ° 768 ç»´çš„å¯†é›†å‘é‡
- åŸºäº MacBERT-base æ¶æ„ï¼ˆ12å±‚ Transformerï¼Œ768 hiddenï¼‰
- é‡‡ç”¨ CoSENT è®­ç»ƒæ–¹å¼ï¼Œä¸“é—¨ä¼˜åŒ–è¯­ä¹‰ç›¸ä¼¼åº¦
- åœ¨ä¸­æ–‡ STS / ç›¸ä¼¼åº¦ä»»åŠ¡ä¸Šè¡¨ç°ç¨³å®š

2. BGE-base-zh

BAAI BGEï¼ˆBeijing General Embeddingï¼‰ç³»åˆ—æ˜¯é«˜è´¨é‡ä¸­è‹±æ–‡å‘é‡æ¨¡å‹ã€‚
å…¶ä¸­ï¼š BAAI / Hugging Face ä¸Šçš„ bge-base-zh æ˜¯ä¸€ä¸ª ä¸­æ–‡ embedding æ¨¡å‹ï¼ˆ768 ç»´ï¼‰

